{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options as FFOptions\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "\n",
    "from pathlib import Path\n",
    "user_profile =  Path(\"user_data/test1\").absolute()\n",
    "user_profile.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "options = FFOptions()\n",
    "options.add_argument(\"-profile\")\n",
    "options.add_argument(str(user_profile))\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "TOtalPostID = []\n",
    "TOtalauthor = []\n",
    "TOtalPostcontent = []\n",
    "TOtalReaction = []\n",
    "TOtalReactionList = []\n",
    "TOtalSeenbyN = []\n",
    "TOtalSeenbyList = []\n",
    "TOtalCommentN = []\n",
    "TOtalCommentList = []\n",
    "TOtalPostURL = []\n",
    "\n",
    "driver.get(\"https://www.facebook.com/\")\n",
    "\n",
    "input1=(\"請輸入社團連結\")\n",
    "input2=(\"請輸入臉書帳號\")\n",
    "input3=(\"請輸入臉書密碼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 輸入社團連結&最新一篇貼文的日期\n",
    "url=input1\n",
    "\n",
    "# 社團名字、社團ID、社團人數\n",
    "driver.get((url))\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')        \n",
    "cbnfind = soup.find_all('a', class_='x1i10hfl xjbqb8w x1ejq31n xd10rxx x1sy0etr x17r0tee x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1heor9g xt0b8zv x1xlr1w8')\n",
    "cbflist = []\n",
    "for i in cbnfind:\n",
    "    cbflist.append(i.text)\n",
    "\n",
    "clubname=cbflist[0]\n",
    "clubID=url.split(\"groups/\")[1]\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')        \n",
    "cbmNfind = soup.find_all('a', class_='x1i10hfl xjbqb8w x1ejq31n xd10rxx x1sy0etr x17r0tee x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz xt0b8zv xi81zsa x1s688f')\n",
    "cbmNlist = []\n",
    "for i in cbmNfind:\n",
    "    cbmNlist.append(i.text)\n",
    "cbmN=cbmNlist[0][:-4]\n",
    "\n",
    "# main\n",
    "cleaned_links=[]\n",
    "target=0\n",
    "while target != clubname:\n",
    "    post_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/posts/']\")\n",
    "    for i in post_links:\n",
    "        href = i.get_attribute(\"href\")\n",
    "        cleaned_href = href.split(\"?\", 1)[0]\n",
    "        cleaned_links.append(cleaned_href)\n",
    "    y = driver.execute_script(\"return window.scrollY\")\n",
    "    driver.execute_script(f\"window.scrollTo(0, {y+300})\")\n",
    "    dt = driver.find_elements(By.CSS_SELECTOR, \"span.x4k7w5x > a\")\n",
    "    for i in dt:\n",
    "        try:\n",
    "            ActionChains(driver).move_to_element(i).perform()\n",
    "        except:\n",
    "            pass\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')         \n",
    "    scctfind = soup.find_all('h3', class_='x1heor9g x1qlqyl8 x1pd3egz x1a2a7pz x1gslohp x1yc453h')\n",
    "    scct = []\n",
    "    for i in scctfind:\n",
    "        scct.append(i.text)\n",
    "    # postN=len(scct)\n",
    "    lastone=scct[-1]\n",
    "    xtn=len(lastone)-3-(len(clubname))\n",
    "    target=lastone[xtn:-3]\n",
    "\n",
    "\n",
    "# link\n",
    "\n",
    "post_links = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/posts/']\")\n",
    "for i in post_links:\n",
    "    href = i.get_attribute(\"href\")\n",
    "    cleaned_href = href.split(\"?\", 1)[0]\n",
    "    cleaned_links.append(cleaned_href)\n",
    "\n",
    "distinct_links = []\n",
    "for x in cleaned_links:\n",
    "    if x in distinct_links:\n",
    "        continue\n",
    "    else:\n",
    "        distinct_links.append(x)\n",
    "\n",
    "TOtalPostURL=[]\n",
    "for b in distinct_links:\n",
    "    TOtalPostURL.append(b)\n",
    "Changelist=[]\n",
    "clubIDN=len(clubID)+20\n",
    "for i in range(len(TOtalPostURL)):\n",
    "    if TOtalPostURL[i].split(\"//www.\")[1][:clubIDN] != f\"facebook.com/groups/{clubID}\":\n",
    "        TOtalPostURL[i]=\"ErVurl\"\n",
    "        Changelist.append(str(i))\n",
    "ErvToBeRemoved1=\"ErVurl\"\n",
    "try:\n",
    "    while True:\n",
    "        TOtalPostURL.remove(ErvToBeRemoved1)\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korp=0\n",
    "start=0\n",
    "for p in range(len(TOtalPostURL)-int(start)):\n",
    "    kp=int(p)+int(start)\n",
    "    korp+=1\n",
    "    # postID\n",
    "    postid=TOtalPostURL[kp].split(\"/posts/\")[1].rstrip(\"/\")\n",
    "    driver.get(TOtalPostURL[kp])\n",
    "    time.sleep(2)\n",
    "    TOtalPostID.append(postid)\n",
    "    \n",
    "    # Author name\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')         \n",
    "    authnornfind = soup.find('h3', class_='x1heor9g x1qlqyl8 x1pd3egz x1a2a7pz x1gslohp x1yc453h')\n",
    "    TOtalauthor.append(authnornfind.text)\n",
    "    \n",
    "    # Postcontent\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div[2]/div/div/div[4]/div/div/div/div/div/div/div[1]/div/div/div/div/div/div/div/div/div/div/div[8]/div/div/div[3]/div[1]\") != None:\n",
    "            postcontent=driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div[2]/div/div/div[4]/div/div/div/div/div/div/div[1]/div/div/div/div/div/div/div/div/div/div/div[8]/div/div/div[3]/div[1]\").text\n",
    "    except:\n",
    "        postcontent=\"no content\"\n",
    "\n",
    "    picfind=[]\n",
    "    try:\n",
    "        if driver.find_elements(By.XPATH, '//img[@class=\"xz74otr x1ey2m1c xds687c x5yr21d x10l6tqk x17qophe x13vifvy xh8yej3\"]')[0] != None:\n",
    "            picetfind = driver.find_elements(By.XPATH, '//img[@class=\"xz74otr x1ey2m1c xds687c x5yr21d x10l6tqk x17qophe x13vifvy xh8yej3\"]')\n",
    "            picfind=[]\n",
    "            picct=0\n",
    "            for i in picetfind:\n",
    "                picct+=1\n",
    "                pngname=f\"圖片{picct}:\"\n",
    "                picfind.append(pngname+i.get_attribute(\"src\"))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH, '//img[@class=\"x1ey2m1c xds687c x5yr21d x10l6tqk x17qophe x13vifvy xh8yej3 xl1xv1r\"]') != None:\n",
    "            picetfind = driver.find_element(By.XPATH, '//img[@class=\"x1ey2m1c xds687c x5yr21d x10l6tqk x17qophe x13vifvy xh8yej3 xl1xv1r\"]')\n",
    "            picfind=[]\n",
    "            pngname=\"圖片:\"\n",
    "            picfind.append(pngname+picetfind.get_attribute(\"src\"))  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH, '//video[@class=\"x1lliihq x5yr21d xh8yej3\"]') != None:\n",
    "            picetfind = driver.find_element(By.XPATH, '//video[@class=\"x1lliihq x5yr21d xh8yej3\"]')\n",
    "            picfind=[]\n",
    "            pngname=\"影片:\"\n",
    "            picfind.append(pngname+picetfind.get_attribute(\"src\"))  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if picfind != []:\n",
    "        picfind2=\"\\n\".join(map(str, picfind))\n",
    "    else:\n",
    "        picfind2=\"no pictures or video\"\n",
    "    \n",
    "    mixedcontent=postcontent+\"\\n\"+picfind2\n",
    "    TOtalPostcontent.append(mixedcontent)\n",
    "    \n",
    "    # Seen \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')        \n",
    "    seen = soup.find_all('span', class_='x193iq5w xeuugli x13faqbe x1vvkbs xlh3980 xvmahel x1n0sxbx x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x3x7a5m x6prxxf xvq8zen xo1l8bm xi81zsa')\n",
    "    slist = []\n",
    "    for i in seen:\n",
    "        slist.append(i.text)\n",
    "    \n",
    "    try:\n",
    "        if slist[0][-8:]==\"回應了這張相片。\":\n",
    "                slist.pop(0)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if slist!=[]:\n",
    "        if len(slist) != 1:\n",
    "            commentN=(slist[0]).rstrip(\"則留言\")\n",
    "        else:\n",
    "            commentN=\"no comment\"\n",
    "\n",
    "        if len(slist) != 1 and slist[1]==\"所有人都已看過\":\n",
    "            seenN=str(int(cbmN)-2)\n",
    "        elif len(slist) == 1 and slist[0]==\"所有人都已看過\":\n",
    "            seenN=str(int(cbmN)-2)\n",
    "        elif len(slist) != 1 :\n",
    "            seenN=str(int((slist[1]).rstrip(\"人已看過\"))-1)\n",
    "        else:    \n",
    "            seenN=str(int((slist[0]).rstrip(\"人已看過\"))-1)\n",
    "    else:\n",
    "        commentN=\"no comment\"\n",
    "        seenN=\"此貼文未顯示看過人數\"\n",
    "\n",
    "    driver.find_element(By.XPATH, '//span[contains(text(),\"已看過\")]').click()\n",
    "    time.sleep(1)\n",
    "    ct=0\n",
    "    while ct < int(seenN):\n",
    "        pane = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div[3]\")\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", pane)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')  \n",
    "        sbname = soup.find_all('span', class_='x193iq5w xeuugli x13faqbe x1vvkbs xlh3980 xvmahel x1n0sxbx x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x3x7a5m x6prxxf xvq8zen xk50ysn xzsf02u x1yc453h')\n",
    "        ct=int(len(sbname))\n",
    "\n",
    "    sbnamelist = []\n",
    "    for i in sbname:\n",
    "        sbnamelist.append(i.text)\n",
    "\n",
    "    sbclose=driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div[2]/div/i\").click()\n",
    "    seebylistjoint = \"、\".join(map(str, sbnamelist))\n",
    "\n",
    "    TOtalSeenbyN.append(seenN)\n",
    "    TOtalCommentN.append(commentN)\n",
    "    TOtalSeenbyList.append(seebylistjoint)\n",
    "    \n",
    "    # reaction\n",
    "    idt=0\n",
    "    try:\n",
    "        while driver.find_elements(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div[2]/div/div/div[4]/div/div/div/div/div/div/div[1]/div/div/div/div/div/div/div/div/div/div/div[8]/div/div/div[4]/div/div/div[1]/div/div[1]/div/div[1]/div/span/div/span[2]/span/span\")[0] != None:\n",
    "            driver.find_elements(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div[2]/div/div/div[4]/div/div/div/div/div/div/div[1]/div/div/div/div/div/div/div/div/div/div/div[8]/div/div/div[4]/div/div/div[1]/div/div[1]/div/div[1]/div/span/div/span[2]/span/span\")[0].click()\n",
    "            idt=1\n",
    "            time.sleep(0.5)\n",
    "    except :\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        while driver.find_elements(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div[2]/div/div/div[4]/div/div/div/div/div/div/div[1]/div/div/div/div/div/div/div/div/div/div/div[8]/div/div/div[5]/div/div/div[1]/div/div[1]/div/div[1]/div/span/div/span[2]/span/span\")[0] != None:\n",
    "            driver.find_elements(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div[2]/div/div/div[4]/div/div/div/div/div/div/div[1]/div/div/div/div/div/div/div/div/div/div/div[8]/div/div/div[5]/div/div/div[1]/div/div[1]/div/div[1]/div/span/div/span[2]/span/span\")[0].click()\n",
    "            idt=1\n",
    "            time.sleep(0.3)\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')        \n",
    "    rtlist = soup.find_all('div', class_='x1i10hfl xe8uvvx xggy1nq x1o1ewxj x3x9cwd x1e5q0jg x13rtm0m x87ps6o x1lku1pv x1a2a7pz xjyslct xjbqb8w x18o3ruo x13fuv20 xu3j5b3 x1q0q8m5 x26u7qi x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1heor9g x1ypdohk xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x1n2onr6 x16tdsg8 x1hl2dhg x1vjfegm x3nfvp2 xrbpyxo xng8ra x16dsc37')\n",
    "    rt = \"\".join(map(str, rtlist))\n",
    "    rt = rt.split(\"aria-label=\")\n",
    "    rt.pop(0)\n",
    "\n",
    "    rt2=[]\n",
    "    for i in range(len(rt)):\n",
    "        rt[i]=(rt[i].split(\"aria-selected=\"))[0]\n",
    "        rt2.append(rt[i])\n",
    "\n",
    "    if idt != 0:\n",
    "        rtresult=rt2\n",
    "    else:\n",
    "        rtresult=\"no reaction\"\n",
    "\n",
    "    rtnamelist = []\n",
    "\n",
    "    if rtresult !=\"no reaction\" and len(rtresult) > 1 :    \n",
    "        for i in range((len(rtresult))-1):\n",
    "            rtag=f'//div[@aria-label={rtresult[i+1]}]'\n",
    "            driver.find_element(By.XPATH, rtag).click()\n",
    "            time.sleep(3)\n",
    "            rtct=0\n",
    "            rtype=rtresult[i+1].split(\",\")[0][1:]\n",
    "            rtnbr=(rtresult[i+1].split(\" \"))[1][:-1]\n",
    "            rtttyp=f\"按{rtype}的有{rtnbr}人:\"\n",
    "            rtnamelist.append(rtttyp)\n",
    "            time.sleep(0.8)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')  \n",
    "            rtname = soup.find_all('span', class_='x193iq5w xeuugli x13faqbe x1vvkbs xlh3980 xvmahel x1n0sxbx x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x3x7a5m x6prxxf xvq8zen xk50ysn xzsf02u x1yc453h')\n",
    "            rtct=int(len(rtname))\n",
    "            for j in rtname:\n",
    "                rtnamelist.append(j.text+\"、\")\n",
    "    elif rtresult !=\"no reaction\" and len(rtresult) == 1:\n",
    "        rtag=f'//div[@aria-label={rtresult[0]}]'\n",
    "        driver.find_element(By.XPATH, rtag).click()\n",
    "        time.sleep(3)\n",
    "        rtct=0\n",
    "        rtype=rtresult[0].split(\",\")[0][1:]\n",
    "        rtnbr=(rtresult[0].split(\" \"))[1][:-1]\n",
    "        rtttyp=f\"按{rtype}的有{rtnbr}人:\"\n",
    "        rtnamelist.append(rtttyp)\n",
    "        time.sleep(0.8)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')  \n",
    "        rtname = soup.find_all('span', class_='x193iq5w xeuugli x13faqbe x1vvkbs xlh3980 xvmahel x1n0sxbx x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x3x7a5m x6prxxf xvq8zen xk50ysn xzsf02u x1yc453h')\n",
    "        rtct=int(len(rtname))\n",
    "        for j in rtname:\n",
    "            rtnamelist.append(j.text+\"、\")\n",
    "    else:\n",
    "        rtnamelist.append(\"no reaction\")\n",
    "\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        while driver.find_elements(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div/div/div/div[1]/div/div[2]/div\")[0] != None:\n",
    "            driver.find_elements(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[4]/div/div/div[1]/div/div[2]/div/div/div/div/div/div/div[1]/div/div[2]/div\")[0].click()\n",
    "            time.sleep(0.3)\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "    rtrt2= \"\".join(map(str, rtresult))\n",
    "    if rtrt2 !=\"no reaction\":\n",
    "        rtresult2=f\"這篇貼文的互動：{rtrt2}\"\n",
    "    else:\n",
    "        rtresult2=\"no reaction\"\n",
    "\n",
    "    if rtnamelist[0] !=\"no reaction\":\n",
    "        rtnamelist2=\" \".join(map(str, rtnamelist))\n",
    "    else:\n",
    "        rtnamelist2=\"no reaction\"\n",
    "    \n",
    "    TOtalReaction.append(rtresult2)\n",
    "    TOtalReactionList.append(rtnamelist2)\n",
    "\n",
    "    # TOtalReaction.append(\"系統錯誤,暫時無法獲得此資訊\")\n",
    "    # TOtalReactionList.append(\"系統錯誤,暫時無法獲得此資訊\")\n",
    "\n",
    "    if commentN != \"no comment\":\n",
    "        try:\n",
    "            cmt1=driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div[2]/div/div/div[4]/div/div/div/div/div/div/div[1]/div/div/div/div/div/div/div/div/div/div/div[8]/div/div/div[4]/div/div/div[2]/div[2]/div/div/span\").click()\n",
    "            time.sleep(0.8)\n",
    "            cmt2=driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[2]/div/div/div[1]/div[1]/div/div/div/div/div/div/div[1]/div/div[2]/div[1]/div/div[1]/span\").click()\n",
    "            time.sleep(0.8)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        y = driver.execute_script(\"return window.scrollY\")\n",
    "        driver.execute_script(f\"window.scrollTo(0, {y + 600})\")\n",
    "        time.sleep(0.8)\n",
    "        \n",
    "        # 點擊查看更多貼文\n",
    "        try:\n",
    "            while driver.find_elements(By.XPATH, '//span[contains(text(),\"查看更多留言\")]')[0] != None:\n",
    "                driver.find_elements(By.XPATH, '//span[contains(text(),\"查看更多留言\")]')[0].click()\n",
    "                y = driver.execute_script(\"return window.scrollY\")\n",
    "                driver.execute_script(f\"window.scrollTo(0, {y + 600})\")\n",
    "                time.sleep(1)\n",
    "        except :\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            while driver.find_elements(By.XPATH, '//span[contains(text(),\"檢視\")]')[0] != None:\n",
    "                driver.find_elements(By.XPATH, '//span[contains(text(),\"檢視\")]')[0].click()\n",
    "                y = driver.execute_script(\"return window.scrollY\")\n",
    "                driver.execute_script(f\"window.scrollTo(0, {y + 600})\")\n",
    "                time.sleep(1)\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "                \n",
    "        try:\n",
    "            while driver.find_elements(By.XPATH, '//span[contains(text(),\"查看另\")]')[0] != None:\n",
    "                driver.find_elements(By.XPATH, '//span[contains(text(),\"查看另\")]')[0].click()\n",
    "                y = driver.execute_script(\"return window.scrollY\")\n",
    "                driver.execute_script(f\"window.scrollTo(0, {y + 600})\")\n",
    "                time.sleep(1)\n",
    "        except :\n",
    "            pass\n",
    "        \n",
    "        # 點開回覆\n",
    "        try:\n",
    "            while driver.find_elements(By.XPATH, '//div[contains(text(),\"已回覆\")]')[0] != None:\n",
    "                driver.find_elements(By.XPATH, '//div[contains(text(),\"已回覆\")]')[0].click()\n",
    "                time.sleep(0.3)\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "        # 點開所有留言(查看更多)\n",
    "        try:\n",
    "            while driver.find_elements(By.XPATH, '//div[contains(text(),\"查看更多\")]')[0] != None:\n",
    "                driver.find_elements(By.XPATH, '//div[contains(text(),\"查看更多\")]')[0].click()\n",
    "                time.sleep(0.3)\n",
    "        except :\n",
    "            pass\n",
    "        \n",
    "        # 抓取留言\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')        \n",
    "\n",
    "        # 抓取留言者姓名\n",
    "        allcmtname = soup.find_all('a', class_='x1i10hfl xjbqb8w x1ejq31n xd10rxx x1sy0etr x17r0tee x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1heor9g xt0b8zv')\n",
    "        allcmtnamelist = []\n",
    "        for i in allcmtname:\n",
    "            allcmtnamelist.append(i.text)\n",
    "        allcmtnamelist.pop(0)\n",
    "\n",
    "        # 處理重複留言者的姓名\n",
    "        counts={}\n",
    "        for index, key in enumerate(allcmtnamelist):\n",
    "            if key in counts:\n",
    "                counts[key]+=1\n",
    "                allcmtnamelist[index]=f\"{key}_.{counts[key]}\"\n",
    "            else:\n",
    "                counts[key]=0\n",
    "\n",
    "        # 抓取留言本體\n",
    "        allcmtct = soup.find_all('span', class_='x193iq5w xeuugli x13faqbe x1vvkbs xlh3980 xvmahel x1n0sxbx x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x3x7a5m x6prxxf xvq8zen xo1l8bm xzsf02u')\n",
    "        allcmtctlist = []\n",
    "        for i in allcmtct:\n",
    "            allcmtctlist.append(i.text)\n",
    "\n",
    "\n",
    "        # 處理其他值\n",
    "        valueToBeRemoved=\"Facebook\"\n",
    "        try:\n",
    "            while True:\n",
    "                allcmtctlist.remove(valueToBeRemoved)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    else:\n",
    "        allcmtctlist=\"no comment\"\n",
    "        allcmtnamelist=\"no comment\"\n",
    "\n",
    "    commentjointlist=[]\n",
    "    if commentN != \"no comment\":\n",
    "        try:\n",
    "            for i in range(int(commentN)):\n",
    "                commentjointlist.append(allcmtnamelist[i]+\":\"+allcmtctlist[i])\n",
    "            commentjoint = \"\\n\".join(map(str, commentjointlist))\n",
    "        except:\n",
    "            commentjoint=\"留言中含有純圖片的回覆\"\n",
    "    else:\n",
    "        commentjoint=\"no comment\"\n",
    "\n",
    "    TOtalCommentList.append(commentjoint)\n",
    "    time.sleep(2)\n",
    "\n",
    "dict = {\"PostID\": TOtalPostID, \n",
    "        \"author\": TOtalauthor, \n",
    "        \"Post content\": TOtalPostcontent, \n",
    "        \"Reaction\": TOtalReaction,   \n",
    "        \"Reaction List\": TOtalReactionList, \n",
    "        \"SeenbyN\": TOtalSeenbyN,\n",
    "        \"Seenby List\": TOtalSeenbyList, \n",
    "        \"CommentN\": TOtalCommentN,\n",
    "        \"Comment List\": TOtalCommentList,\n",
    "        \"Post URL\": TOtalPostURL\n",
    "       }\n",
    "\n",
    "allresult = pd.DataFrame(dict)\n",
    "csvname=f\"{clubname}.csv\"\n",
    "allresult.to_csv(csvname)\n",
    "\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
